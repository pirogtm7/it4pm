{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import Dataset\n",
    "from llama_fine_tuning_util import load_trace_data, load_pairs_data, load_next_activity_data\n",
    "\n",
    "def calculate_tsad_statistics(dataset: Dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    total_samples = len(df)\n",
    "    valid_samples = (df[\"ds_labels\"] == \"True\").sum()\n",
    "    anomalous_samples = (df[\"ds_labels\"] == \"False\").sum()\n",
    "    trace_lengths = df[\"trace\"].apply(len)\n",
    "    \n",
    "    min_length = trace_lengths.min()\n",
    "    max_length = trace_lengths.max()\n",
    "    mean_length = trace_lengths.mean()\n",
    "    median_length = trace_lengths.median()\n",
    "    \n",
    "    print(f\"T-SAD Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Valid samples: {valid_samples}\")\n",
    "    print(f\"Anomalous samples: {anomalous_samples}\")\n",
    "    print(f\"Trace length: min={min_length}, max={max_length}, mean={mean_length:.2f}, median={median_length}\")\n",
    "\n",
    "def calculate_asad_statistics(dataset: Dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    total_samples = len(df)\n",
    "    valid_samples = (df[\"ds_labels\"] == \"True\").sum()\n",
    "    anomalous_samples = (df[\"ds_labels\"] == \"False\").sum()\n",
    "\n",
    "    print(f\"\\nA-SAD Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Valid samples: {valid_samples}\")\n",
    "    print(f\"Anomalous samples: {anomalous_samples}\")\n",
    "\n",
    "def calculate_snap_statistics(dataset: Dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    total_samples = len(df)\n",
    "    prefix_lengths = df[\"prefix\"].apply(len)\n",
    "    \n",
    "    min_length = prefix_lengths.min()\n",
    "    max_length = prefix_lengths.max()\n",
    "    mean_length = prefix_lengths.mean()\n",
    "    median_length = prefix_lengths.median()\n",
    "    \n",
    "    print(f\"\\nS-NAP Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Prefix length: min={min_length}, max={max_length}, mean={mean_length:.2f}, median={median_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_train, trace_val, trace_test = load_trace_data()\n",
    "pairs_train, pairs_val, pairs_test = load_pairs_data()\n",
    "snap_train, snap_val, snap_test = load_next_activity_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95173b0026f4474f9fd652551304a722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/26978 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66610e73315f45b598fbf5c4cab84a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/26978 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "label_column = \"ds_labels\"\n",
    "positive_samples_full = trace_val.filter(lambda x: x[label_column] == \"True\")\n",
    "negative_samples_full = trace_val.filter(lambda x: x[label_column] == \"False\")\n",
    "max_samples_per_class = 2 * min(positive_samples_full.num_rows, negative_samples_full.num_rows)\n",
    "\n",
    "samples_per_class = max_samples_per_class // 2\n",
    "\n",
    "# Separate positive and negative samples\n",
    "positive_samples = positive_samples_full.shuffle(seed=4).select(range(samples_per_class))\n",
    "negative_samples = negative_samples_full.shuffle(seed=4).select(range(samples_per_class))\n",
    "trace_val = concatenate_datasets([positive_samples, negative_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c9a7cd7f794f6faebae586ace9b916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9d4ca380374214a1d0fc4448cfa04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "label_column = \"ds_labels\"\n",
    "positive_samples_full = trace_test.filter(lambda x: x[label_column] == \"True\")\n",
    "negative_samples_full = trace_test.filter(lambda x: x[label_column] == \"False\")\n",
    "max_samples_per_class = 2 * min(positive_samples_full.num_rows, negative_samples_full.num_rows)\n",
    "\n",
    "samples_per_class = max_samples_per_class // 2\n",
    "\n",
    "# Separate positive and negative samples\n",
    "positive_samples = positive_samples_full.shuffle(seed=4).select(range(samples_per_class))\n",
    "negative_samples = negative_samples_full.shuffle(seed=4).select(range(samples_per_class))\n",
    "trace_test = concatenate_datasets([positive_samples, negative_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'trace', 'ds_labels', 'id', 'num_unique_activities'],\n",
      "    num_rows: 184304\n",
      "})\n",
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'eventually_follows', 'ds_labels', 'id', 'num_unique_activities'],\n",
      "    num_rows: 316308\n",
      "})\n",
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'trace', 'prefix', 'next', 'id', 'num_unique_activities'],\n",
      "    num_rows: 575339\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(trace_all)\n",
    "print(pairs_all)\n",
    "print(snap_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_all = concatenate_datasets([trace_train, trace_val, trace_test])\n",
    "pairs_all = concatenate_datasets([pairs_train, pairs_val, pairs_test])\n",
    "snap_all = concatenate_datasets([snap_train, snap_val, snap_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SAD Statistics:\n",
      "Total samples: 184304\n",
      "Valid samples: 93415\n",
      "Anomalous samples: 90889\n",
      "Trace length: min=2, max=10, mean=7.26, median=8.0\n",
      "\n",
      "A-SAD Statistics:\n",
      "Total samples: 316308\n",
      "Valid samples: 158154\n",
      "Anomalous samples: 158154\n",
      "\n",
      "S-NAP Statistics:\n",
      "Total samples: 575339\n",
      "Prefix length: min=1, max=9, mean=5.67, median=6.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "calculate_tsad_statistics(trace_all)\n",
    "# 16549 + 16549 = valid + test (equal)\n",
    "# 74340 + 76866 = train\n",
    "\n",
    "calculate_asad_statistics(pairs_all)\n",
    "calculate_snap_statistics(snap_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from llama_fine_tuning_util import load_discovery_data\n",
    "\n",
    "def calculate_sdfd_statistics(dataset: Dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    total_samples = len(df)\n",
    "    \n",
    "    # Parse DFGs\n",
    "    df[\"dfg_parsed\"] = df[\"dfg\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    edge_counts = df[\"dfg_parsed\"].apply(len)\n",
    "\n",
    "    min_edges = edge_counts.min()\n",
    "    max_edges = edge_counts.max()\n",
    "    mean_edges = edge_counts.mean()\n",
    "    median_edges = edge_counts.median()\n",
    "\n",
    "    print(f\"\\nS-DFD Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Edges: min={min_edges}, max={max_edges}, mean={mean_edges:.2f}, median={median_edges}\")\n",
    "\n",
    "def calculate_sptd_operator_distribution(dataset):\n",
    "    # Convert to pandas DataFrame\n",
    "    df = dataset.to_pandas()\n",
    "\n",
    "    # Initialize operator counters\n",
    "    operators = {\"->\": 0, \"+\": 0, \"X\": 0, \"*\": 0}\n",
    "\n",
    "    # Count operators in each pt string\n",
    "    for pt_text in df[\"pt\"]:\n",
    "        if isinstance(pt_text, str):\n",
    "            operators[\"->\"] += pt_text.count(\"->\")\n",
    "            operators[\"+\"]  += pt_text.count(\"+\")\n",
    "            operators[\"X\"]  += pt_text.count(\"X\")\n",
    "            operators[\"*\"]  += pt_text.count(\"*\")\n",
    "\n",
    "    # Calculate total operators counted\n",
    "    total_ops = sum(operators.values())\n",
    "\n",
    "    print(\"=== S-PTD Operator Distribution ===\")\n",
    "    for op, count in operators.items():\n",
    "        percentage = (count / total_ops) * 100 if total_ops > 0 else 0\n",
    "        print(f\"{op}: {count} occurrences ({percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discovery splits\n",
    "discovery_train, discovery_val, discovery_test = load_discovery_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'dfg', 'pt', 'id', 'num_unique_activities'],\n",
      "    num_rows: 11311\n",
      "})\n",
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'dfg', 'pt', 'id', 'num_unique_activities'],\n",
      "    num_rows: 2745\n",
      "})\n",
      "Dataset({\n",
      "    features: ['model_id', 'revision_id', 'unique_activities', 'dfg', 'pt', 'id', 'num_unique_activities'],\n",
      "    num_rows: 1524\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(discovery_train)\n",
    "print(discovery_val)\n",
    "print(discovery_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S-DFD Statistics:\n",
      "Total samples: 15580\n",
      "Edges: min=1, max=87, mean=5.22, median=4.0\n",
      "=== S-PTD Operator Distribution ===\n",
      "->: 18676 occurrences (70.15%)\n",
      "+: 3537 occurrences (13.29%)\n",
      "X: 4202 occurrences (15.78%)\n",
      "*: 209 occurrences (0.79%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine splits\n",
    "discovery_all = concatenate_datasets([discovery_train, discovery_val, discovery_test])\n",
    "\n",
    "# Calculate statistics\n",
    "calculate_sdfd_statistics(discovery_all)\n",
    "calculate_sptd_operator_distribution(discovery_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms4pm_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
